{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch jit trace usage\n",
    "\n",
    "Author Diluka H.\n",
    "\n",
    "Torch jit trace can be used to save a trained model to a file \"model.pt\" and then load it and retrain it without original code, as long as there are no switch or if statements in the model class.\n",
    "\n",
    "1. Training the model.\n",
    "2. Save the model.\n",
    "3. Load the trained model. This section is standalone and can be run by itself even if you restart the jupyter kernel indepened of the other sections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=13456, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=8, bias=True)\n",
      ")\n",
      "Epoch:  0 Loss:  2.3040506839752197\n",
      "Epoch:  1 Loss:  1.9797697067260742\n",
      "Epoch:  2 Loss:  1.6775538921356201\n",
      "Epoch:  3 Loss:  1.5693578720092773\n",
      "Epoch:  4 Loss:  1.4593698978424072\n",
      "Epoch:  5 Loss:  1.3346567153930664\n",
      "Epoch:  6 Loss:  1.3202340602874756\n",
      "Epoch:  7 Loss:  1.321162223815918\n",
      "Epoch:  8 Loss:  1.2872483730316162\n",
      "Epoch:  9 Loss:  1.2617595195770264\n",
      "Epoch:  10 Loss:  1.190783143043518\n",
      "Epoch:  11 Loss:  1.2801188230514526\n",
      "Epoch:  12 Loss:  1.2691946029663086\n",
      "Epoch:  13 Loss:  1.2173444032669067\n",
      "Epoch:  14 Loss:  1.204860806465149\n",
      "Epoch:  15 Loss:  1.284468412399292\n",
      "Epoch:  16 Loss:  1.2324779033660889\n",
      "Epoch:  17 Loss:  1.1393040418624878\n",
      "Epoch:  18 Loss:  1.1703532934188843\n",
      "Epoch:  19 Loss:  1.172365427017212\n",
      "Epoch:  20 Loss:  1.15666925907135\n",
      "Epoch:  21 Loss:  1.1117290258407593\n",
      "Epoch:  22 Loss:  1.0974960327148438\n",
      "Epoch:  23 Loss:  1.1277625560760498\n",
      "Epoch:  24 Loss:  1.0915404558181763\n",
      "Epoch:  25 Loss:  1.0017117261886597\n",
      "Epoch:  26 Loss:  1.0201884508132935\n",
      "Epoch:  27 Loss:  0.9742359519004822\n",
      "Epoch:  28 Loss:  0.9662123322486877\n",
      "Epoch:  29 Loss:  0.9859521985054016\n",
      "Epoch:  30 Loss:  0.9198329448699951\n",
      "Epoch:  31 Loss:  0.9355231523513794\n",
      "Epoch:  32 Loss:  0.8919342160224915\n",
      "Epoch:  33 Loss:  0.8761398196220398\n",
      "Epoch:  34 Loss:  0.8609423637390137\n",
      "Epoch:  35 Loss:  0.8333466649055481\n",
      "Epoch:  36 Loss:  0.8061693906784058\n",
      "Epoch:  37 Loss:  0.7230473160743713\n",
      "Epoch:  38 Loss:  0.7867627143859863\n",
      "Epoch:  39 Loss:  0.7329268455505371\n",
      "Epoch:  40 Loss:  0.7505301833152771\n",
      "Epoch:  41 Loss:  0.6820194125175476\n",
      "Epoch:  42 Loss:  0.6605116128921509\n",
      "Epoch:  43 Loss:  0.6716940402984619\n",
      "Epoch:  44 Loss:  0.6919913291931152\n",
      "Epoch:  45 Loss:  0.6226816773414612\n",
      "Epoch:  46 Loss:  0.6647891998291016\n",
      "Epoch:  47 Loss:  0.6291108131408691\n",
      "Epoch:  48 Loss:  0.6098330020904541\n",
      "Epoch:  49 Loss:  0.5839527249336243\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # an affine operation: y = Wx + b\n",
    "        #How calculate inputs to linear layer https://datascience.stackexchange.com/questions/40906/determining-size-of-fc-layer-after-conv-layer-in-pytorch\n",
    "        self.fc1 = nn.Linear(13456, 120)  # 5*5 from image dimension # orginal was 16 * 5 * 5 for a 32x32 image\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))#128 -5 = 123 6*123*123 # after maxpool\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "epochs = 50\n",
    "batchSize = 10\n",
    "#Load dataset\n",
    "tensor_x = torch.tensor(np.load('data.npy')).unsqueeze(1)\n",
    "tensor_y = torch.tensor(np.load('currents.npy'))\n",
    "#print(tensor_x.shape)\n",
    "#print(tensor_y.shape)\n",
    "dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "dataLoader = DataLoader(dataset,batch_size=batchSize, shuffle=True)\n",
    "\n",
    "#for x,y in dataLoader:\n",
    "#    print(x)\n",
    "#    print(y)\n",
    "#    break\n",
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "model.float()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "model.train()\n",
    "lossHistory = []\n",
    "for epoch in range(epochs):\n",
    "    lossTotal = 0\n",
    "    for x,y in dataLoader:\n",
    "        model.zero_grad()                \n",
    "        yhat= model(x.float())\n",
    "        loss = criterion(yhat.view(-1),y.float().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossTotal +=loss\n",
    "    lossHistory.append(lossTotal.detach().numpy())\n",
    "    #https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor\n",
    "    print(\"Epoch: \",epoch, \"Loss: \",lossTotal.item())\n",
    "        \n",
    "#plt.plot(lossHistory)\n",
    "#plt.title('Loss')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0372,  0.3695,  0.9205,  0.3139,  1.1918,  0.4809,  0.2466, -0.0688],\n",
      "        [ 0.2344,  1.1551,  0.2446,  0.0195,  0.2172,  0.3406,  1.3210,  0.3527]])\n"
     ]
    }
   ],
   "source": [
    "#Save Model\n",
    "saveModelPath = \"NN_Model_Checkpoint/model.pth\"\n",
    "with torch.no_grad():\n",
    "    print(model(x.float()))\n",
    "    traced_cell = torch.jit.trace(model, (x.float()))\n",
    "torch.jit.save(traced_cell, saveModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=Net\n",
      "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "  (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
      "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
      "  (fc3): RecursiveScriptModule(original_name=Linear)\n",
      ")\n",
      "Epoch:  0 Loss:  0.6976651549339294\n",
      "Epoch:  1 Loss:  0.6960465312004089\n",
      "Epoch:  2 Loss:  0.6697688102722168\n",
      "Epoch:  3 Loss:  0.6618806719779968\n",
      "Epoch:  4 Loss:  0.5896336436271667\n",
      "Epoch:  5 Loss:  0.5941463112831116\n",
      "Epoch:  6 Loss:  0.5925495624542236\n",
      "Epoch:  7 Loss:  0.5897407531738281\n",
      "Epoch:  8 Loss:  0.545324444770813\n",
      "Epoch:  9 Loss:  0.6062442064285278\n",
      "Epoch:  10 Loss:  0.5815252661705017\n",
      "Epoch:  11 Loss:  0.5069475173950195\n",
      "Epoch:  12 Loss:  0.5409581065177917\n",
      "Epoch:  13 Loss:  0.57889723777771\n",
      "Epoch:  14 Loss:  0.4760935306549072\n",
      "Epoch:  15 Loss:  0.44365933537483215\n",
      "Epoch:  16 Loss:  0.38971441984176636\n",
      "Epoch:  17 Loss:  0.39124596118927\n",
      "Epoch:  18 Loss:  0.4424299895763397\n",
      "Epoch:  19 Loss:  0.4515896439552307\n",
      "Epoch:  20 Loss:  0.4012114703655243\n",
      "Epoch:  21 Loss:  0.38258907198905945\n",
      "Epoch:  22 Loss:  0.3447907865047455\n",
      "Epoch:  23 Loss:  0.37164703011512756\n",
      "Epoch:  24 Loss:  0.3082306385040283\n",
      "Epoch:  25 Loss:  0.3456178605556488\n",
      "Epoch:  26 Loss:  0.30633077025413513\n",
      "Epoch:  27 Loss:  0.32756850123405457\n",
      "Epoch:  28 Loss:  0.28125518560409546\n",
      "Epoch:  29 Loss:  0.2504962682723999\n",
      "Epoch:  30 Loss:  0.2560107111930847\n",
      "Epoch:  31 Loss:  0.29984861612319946\n",
      "Epoch:  32 Loss:  0.3674342930316925\n",
      "Epoch:  33 Loss:  0.24744610488414764\n",
      "Epoch:  34 Loss:  0.24212546646595\n",
      "Epoch:  35 Loss:  0.24381287395954132\n",
      "Epoch:  36 Loss:  0.25650909543037415\n",
      "Epoch:  37 Loss:  0.272726833820343\n",
      "Epoch:  38 Loss:  0.33556053042411804\n",
      "Epoch:  39 Loss:  0.19078315794467926\n",
      "Epoch:  40 Loss:  0.18334245681762695\n",
      "Epoch:  41 Loss:  0.196161150932312\n",
      "Epoch:  42 Loss:  0.1835305243730545\n",
      "Epoch:  43 Loss:  0.14777512848377228\n",
      "Epoch:  44 Loss:  0.152716264128685\n",
      "Epoch:  45 Loss:  0.18199296295642853\n",
      "Epoch:  46 Loss:  0.17305956780910492\n",
      "Epoch:  47 Loss:  0.1624116599559784\n",
      "Epoch:  48 Loss:  0.15198850631713867\n",
      "Epoch:  49 Loss:  0.23473986983299255\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#Loading the model\n",
    "savedModelPath = \"NN_Model_Checkpoint/model.pth\"\n",
    "jitModel = torch.jit.load(savedModelPath);\n",
    "\n",
    "#Training the loaded model\n",
    "epochs = 50\n",
    "batchSize = 10\n",
    "#Load dataset\n",
    "tensor_x = torch.tensor(np.load('data.npy')).unsqueeze(1)\n",
    "tensor_y = torch.tensor(np.load('currents.npy'))\n",
    "\n",
    "dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "dataLoader = DataLoader(dataset,batch_size=batchSize, shuffle=True)\n",
    "\n",
    "model = jitModel\n",
    "print(model)\n",
    "model.float()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "model.train()\n",
    "lossHistory = []\n",
    "for epoch in range(epochs):\n",
    "    lossTotal = 0\n",
    "    for x,y in dataLoader:\n",
    "        model.zero_grad()                \n",
    "        yhat= model(x.float())\n",
    "        loss = criterion(yhat.view(-1),y.float().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossTotal +=loss\n",
    "    lossHistory.append(lossTotal.detach().numpy())\n",
    "    #https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor\n",
    "    print(\"Epoch: \",epoch, \"Loss: \",lossTotal.item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ce49abbe364458eea610840189e5476549c63af214e1bd03a851639ce4ea16b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
